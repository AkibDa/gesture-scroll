{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T17:24:00.808246Z",
     "start_time": "2026-01-21T17:23:59.745762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install -q mediapipe\n",
    "!pip install -q pyautogui"
   ],
   "id": "4ec8f3d3915fd37d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T17:24:04.868682Z",
     "start_time": "2026-01-21T17:24:00.816198Z"
    }
   },
   "cell_type": "code",
   "source": "!curl -o hand_landmarker.task https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task",
   "id": "af2afeece081fe52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100 7635k  100 7635k    0     0  1897k      0  0:00:04  0:00:03  0:00:01 1897k0     0  1951k      0  0:00:03  0:00:03 --:--:-- 1951k\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-21T17:24:05.456711Z",
     "start_time": "2026-01-21T17:24:04.944116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "import util"
   ],
   "id": "e5c026b5cd56ce72",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T17:24:05.606362Z",
     "start_time": "2026-01-21T17:24:05.461478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BaseOptions = mp.tasks.BaseOptions\n",
    "HandLandmarker = mp.tasks.vision.HandLandmarker\n",
    "HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "HAND_CONNECTIONS = [\n",
    "    (0, 1), (1, 2), (2, 3), (3, 4),\n",
    "    (0, 5), (5, 6), (6, 7), (7, 8),\n",
    "    (5, 9), (9, 10), (10, 11), (11, 12),\n",
    "    (9, 13), (13, 14), (14, 15), (15, 16),\n",
    "    (13, 17), (17, 18), (18, 19), (19, 20),\n",
    "    (0, 17)\n",
    "]\n",
    "\n",
    "options = HandLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path='../hand_landmarker.task'),\n",
    "    running_mode=VisionRunningMode.VIDEO,\n",
    "    num_hands=1)\n",
    "\n",
    "detector = HandLandmarker.create_from_options(options)\n",
    "\n",
    "print(\"✅ Success! The detector loaded correctly.\")"
   ],
   "id": "2224a76a7cae7cd2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success! The detector loaded correctly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1769016245.590582  830314 gl_context.cc:407] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1769016245.599336  830317 inference_feedback_manager.cc:121] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1769016245.605034  830322 inference_feedback_manager.cc:121] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T17:24:05.616672Z",
     "start_time": "2026-01-21T17:24:05.614657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def move_mouse(points, frame_shape):\n",
    "    \"\"\"\n",
    "    Moves the mouse cursor based on the position of the Index Finger Tip (8).\n",
    "    points: List of (x,y) tuples representing the hand landmarks.\n",
    "    \"\"\"\n",
    "    if len(points) >= 9:\n",
    "        screen_w, screen_h = pyautogui.size()\n",
    "        frame_h, frame_w = frame_shape\n",
    "        index_finger_tip = points[8]\n",
    "\n",
    "        x = int(index_finger_tip[0] / frame_w * screen_w)\n",
    "        y = int(index_finger_tip[1] / frame_h * screen_h)\n",
    "\n",
    "        pyautogui.moveTo(x, y)"
   ],
   "id": "ed4a94d2d0546ca0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T17:24:05.625900Z",
     "start_time": "2026-01-21T17:24:05.623567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def detect_gestures(frame, points):\n",
    "    \"\"\"\n",
    "    Detects if the Thumb and Index finger are pinching.\n",
    "    points: List of (x,y) tuples representing the hand landmarks.\n",
    "    \"\"\"\n",
    "    if len(points) >= 21:\n",
    "        thumb_tip = points[4]\n",
    "        index_tip = points[8]\n",
    "\n",
    "        cv2.line(frame, thumb_tip, index_tip, (255, 0, 0), 2)\n",
    "\n",
    "        dist = util.get_distance([thumb_tip, index_tip])\n",
    "\n",
    "        if dist < 50 and util.get_angle(points[5], points[6], points[8]) > 90:\n",
    "            cv2.circle(frame, index_tip, 10, (0, 255, 0), -1)\n",
    "            cv2.putText(frame, \"PINCH / CLICK\", (50, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            h, w, _ = frame.shape\n",
    "            move_mouse(points, (h, w))\n",
    "        else:\n",
    "            cv2.putText(frame, f\"Dist: {int(dist)}\", (50, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)"
   ],
   "id": "9916332822e1c5c7",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T17:24:05.634341Z",
     "start_time": "2026-01-21T17:24:05.630852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    is_running = True\n",
    "\n",
    "    try:\n",
    "        while is_running and cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame\")\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            frameRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frameRGB)\n",
    "\n",
    "            frame_timestamp_ms = int(time.time() * 1000)\n",
    "\n",
    "            detection_result = detector.detect_for_video(mp_image, frame_timestamp_ms)\n",
    "\n",
    "            if detection_result.hand_landmarks:\n",
    "                for hand_landmarks in detection_result.hand_landmarks:\n",
    "\n",
    "                    h, w, c = frame.shape\n",
    "                    points = []\n",
    "                    for lm in hand_landmarks:\n",
    "                        cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                        points.append((cx, cy))\n",
    "\n",
    "                    for connection in HAND_CONNECTIONS:\n",
    "                        start_idx = connection[0]\n",
    "                        end_idx = connection[1]\n",
    "                        cv2.line(frame, points[start_idx], points[end_idx], (0, 255, 0), 2)\n",
    "\n",
    "                    for (cx, cy) in points:\n",
    "                        cv2.circle(frame, (cx, cy), 5, (0, 0, 255), -1)\n",
    "\n",
    "                    detect_gestures(frame, points)\n",
    "\n",
    "            cv2.imshow('Webcam', frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                print(\"Quit detected via Keyboard\")\n",
    "                is_running = False\n",
    "            if cv2.getWindowProperty('Webcam', cv2.WND_PROP_VISIBLE) < 1:\n",
    "                print(\"Quit detected via Window Close\")\n",
    "                is_running = False\n",
    "    finally:\n",
    "        print(\"Cleaning up resources...\")\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        detector.close()\n",
    "        for i in range(5):\n",
    "            cv2.waitKey(1)\n",
    "        print(\"Done.\")"
   ],
   "id": "df0944c1712c59e8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T17:25:02.394481Z",
     "start_time": "2026-01-21T17:24:05.641951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "  main()"
   ],
   "id": "8bfabb2671fd7fee",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1769016246.974394  830322 landmark_projection_calculator.cc:81] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quit detected via Keyboard\n",
      "Cleaning up resources...\n",
      "Done.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T17:25:02.439649Z",
     "start_time": "2026-01-21T17:25:02.438300Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d308b580ac6327d9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
